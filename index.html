<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Audiovision Blog</title>

    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>Audiovision Blog</h1>

    <!-- ------------------------------------ WEEK 1 ---------------------------------------------- -->
    <details class="week" id="week-1">
      <summary>Week 1</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          This week introduced sound as an emotional and perceptual experience
          that can guide interpretation and narrative. I was particularly
          interested in the exercise which played a score and we had to guess
          what the intended purpose was. I wrote it as a somber feeling mixed
          with hope, like an anticipation for something better when everything
          is wrong. It was nice to hear everyones perceptions of what they heard
          because they were geared towards the same sound, but different
          answers. It was very impressive when someone got the exact answer, I
          think that attests to how well the sound design was made for it.
        </p>
        <p>
          The Four Ways of Knowing stood out, especially participatory knowing
          (the knowing of feeling what it is like to be in an experience).
          Feeling what its like to be in a situation is very important with
          creating sound design (especially for films or games), even if youve
          never been in that situation yourself. Although it didn't just
          underline the importance to me, it also made me start thinking more
          about how the role of sound can be important for audiences to
          participate more emotionally to a piece of media. A lot of my personal
          projects with sound design have been very focused on realism, but I
          never really thought to consider exactly what I am aiming for with it.
          Am I trying to establish realism to make the visual space more
          believeable and draw attention to it? Am I trying to create certain
          emotions for things that haven't happened on screen? The video shown
          about how sound can change someones perception of visual media also
          led me to think more about it. A moment I found interesting was where
          it explained how sound could shift viewer attention, and how people
          change where they look on the screen based on what they can hear. I
          never really put 2 and 2 together that since I can hint towards
          something sonically, that would change how people perceive the visual
          media, thus changing where they look, maybe anticipating something. I
          just thought that was very interesting that sound can also be a tool
          to guide visual perception.
        </p>

        <h3>Academic Research</h3>
        <p>
          I was inspired by how sound could influence perception, and I ended up
          reading this article by Claudia Gorbman (Narrative Film Music), which
          just talks about how music can guide how people interpret narrative
          meaning. She talked specifically about 'unheard melodies' which is
          basically just how music can support narrative meaning in a subtle
          way, ways that the listener wont really realize unless thinking about
          it. It tied really nicely to what we learnt in class. I also went back
          to this previous paper that I had read previously by Chion. He
          discussed how audio could reflect on visual media in different ways,
          and how you use it is critical. For example, a disconnect in the music
          can create uneasy tension that adds complexity to the visuals, making
          something once seen as normal, into an underlaying feeling of tension.
        </p>

        <h3>Artistic Research</h3>
        <p>
          I started to look more deeply into music and emotions tying together,
          listening to my favorite songs and analysing what musically makes me
          love them so much. A specific example is Let Down by Radiohead. Or any
          radiohead song in general. The way that they build atmosphere, the
          experimental sound, the guiding structure, its moody, its spacey. Even
          i'm not 100% sure the technical reasons of why it makes people feel so
          much. There was a YouTube video I
          <a href="https://www.youtube.com/watch?v=PX2hQdcEvyA">watched</a>
          that I think explained it perfectly, and why it's so good alongside
          visual media. The use of harmony, texture, mood, rhythm. I think its
          refreshing considering a lot of songs nowadays follow certain
          formulas, but that's a completely different topic that I could go
          into.
        </p>

        <h3>Technical Research</h3>
        <p>
          Because of the Gina Moore assignment, i did a lot of research on how
          to use Ableton Live, which is my daw of choice. Experimenting with
          automation and how to make glitches were the highlights. Although I've
          done it automation before, I haven't done it extensively. The more I
          did it the more shocked I was of how it made a difference, especially
          because if I wanted a sound to go away, I just cut it out, but having
          it play soft in the background added that weight I always felt was
          missing from my sound projects. Learning different ways to make
          glitching sounds was really fun. I layered effects like pitch
          shifting, grain delay and reverb and then used automation to create
          sudden cuts, fade ins and randomized movement, which helped me achieve
          that glitch texture I was looking for.
        </p>
        <p>
          Other than Ableton Live, I actually learnt how to compose a simple
          orchestra piece for this assignment. I recognize that scores aren't my
          strong suit and I wanted to do something that challenged me,
          especially since the animation I chose was around 30 seconds, so I
          didn't have to make it too long. I watched
          <a href="https://www.youtube.com/watch?v=ZdhdC2wx2Ew">this video</a>
          which was actually extremely helpful and I learnt many new things. I
          thought the violin and viola were basically the same intstrument
          before this! It was interesting how different instruments in brass,
          woodwind and strings could play the same thing and it gave off
          different emotions and different vibes, even though they were in the
          same frequency spectrum. I particuarly liked the hack of making
          everything on a simple piano, then assigning it to different
          instruments, I definitely think it helped with my workflow as I
          started focusing more on chords and notes and why I wanted to press
          those, rther than being stuck figuring everything all out at once. I
          would highly reccommend that video to anyone looking at how to start
          with orchestral writing.
        </p>

        <h3>Progress Report</h3>
        <p>
          I began by choosing the animation I wanted, then thinking about what
          direction I wanted to go with. This will be written on my report but I
          originally started with a realistic approach but felt that the
          animation was too abstract, and wanted something to fit with that,
          which is why I chose to do a musical score. Of course as mentioned
          before, I chose to do an orchestral piece because of my nonexistent
          experience. Before watching the video I made the mistake of just
          jumping straigh into, which resulted in a terrible score. I just did
          chords and was playing random lead lines within the key, but it
          sounded terrible:
        </p>
        <img src="/photos/week1/original.png" alt="" />
        <p>
          My composition improved greatly after I watched the video. I started
          with a rough piano roll and kept refining it until I had a sound and
          structure I liked which consisted of a lead, a second lead, chords and
          a bass which was all I needed!
        </p>
        <img src="/photos/week1/pianoroll.png" alt="" />
        <p>
          From this I made different groups of the main instruments of strings,
          and assigned the different parts appropriately. The plugin I used was
          BBC's expressive strings, it was super great and useful and free!
        </p>
        <img src="photos/week1/strings.png" alt="" />
        <p>
          then i did the same for brass, using similar mapping techniques to
          fill out the orchestration
        </p>
        <img src="photos/week1/brass.png" alt="" />
        <p>and then woodwinds.</p>
        <img src="photos/week1/woodwind.png" alt="" />
        <p>
          after that it was just a matter of using automation to create
          structure! Then the sound design was finished! Originally it took up
          the entire time, but when I decided that the glitches would turn it
          into synths, I cut the midi short. I used a bunch of random effects
          tomake the glitch sounds as I mentioend earlier, and then to
          transition, I layered a abunch of the elad lines with different sounds
          and textures to lead into the glitchiness, but also give it some
          melodic strucutre so the change wasn't too jarring! This completed my
          first draft and I'm still refining, but I have a structure I like and
          an idea I like so I am happy.
        </p>
        <img src="photos/week1/transition.png" alt="" />
      </div>
    </details>

    <!-- ------------------------------------ WEEK 2 ---------------------------------------------- -->
    <details class="week" id="week-2">
      <summary>Week 2</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          This week in class we analysed the Turn Down for What music video with
          and without sound. I first watched it muted and made notes on what I
          thought the visuals were trying to communicate. Without the audio, it
          felt like a chaotic horror-comedy film where someone’s out of control
          and something is taking over them. The character’s movements were
          exaggerated and crazy, which made the visuals seem comedic, but also
          strange and hard to follow. Without sound, the pacing felt confusing,
          and the structure was harder to grasp.
        </p>
        <p>
          Once the audio was added back in, the whole thing made more sense. The
          music gave it rhythm and energy, making it feel more like a
          conventional music video, where weird visuals are usually expected.
          The sound helped me anticipate moments like when the chorus began, the
          movements got more repetitive and bizarre. it gave the piece form and
          made it easier to follow and highlighted how sound can structure
          visuals and change how we interpret movement.
        </p>
        <p>
          Since I’ve been away, I haven't able to attend the lectures this week,
          but I did get to watch some of my friend's work online. It was really
          inspiring to see how different people approached the same animations
          in their own way, especially because when I was choosing what
          animation to do last assignment, I had my own ideas for each one. It
          was interesting to listen to how they handled mood, timing, and
          transitions, and really hammered in how much creative interpretation
          in sound design is just as important as technical choices.
        </p>

        <h3>Academic Research</h3>
        <p>
          For this week, I mainly referenced two texts that helped shape how I
          approached the Resonance video. The first one was Karen Collins, who
          talked about how ambient textures can help set the emotional tone
          before anything even happens visually. That stuck with me, because I
          start my projecst by focusing on atmosphere rather than realism, and
          it gave me context on why I liked doing that. I wanted the sound to
          slowly evolve and feel like something unstable was underneath, and her
          ideas made me feel more confident in that choice as a lot of the
          people around me usually start with diegetic sound.
        </p>
        <p>
          The second article I read was by Sonnenschein, where he explains how
          different frequency layers being used can create space and shape how
          things feel. I used this information for the narrative arc, using the
          lower frequencies at the start, then evolving the atmosphere by
          introducing different sound frequencies. By balancing the low end
          rumbles with higher pitched textures, it gave the piece more depth,
          like something was exploding.
        </p>

        <h3>Artistic Research</h3>
        <p>
          For this week, I tried to find artists where the music builds mood and
          atmosphere that makes the audience feel emotional. One of them was
          Jeff Buckley, especially his Grace album. Music alone, his use of
          dynamics, reverb and vocal layering creates this haunting and
          immersive sound that really stuck with me. I was especially immersed
          with how his songs often start soft and open, then swells into
          intensity in a yearning way. The switch in dynamics is something that
          influenced how I looked at Resonance.
        </p>
        <p>
          I also listened to Johann Johannsson and his score for Arrival. The
          blending of orchestral instruments with electronic textures felt
          realistic, but otherwordly, which really suited the film. I liked the
          shifts in tone and textures to guide the audience through emotion
          without the need for strong, imposing melodies. It highlights the
          possibility that music can be felt rather than heard, and still have a
          strong impact.
        </p>

        <h3>Technical Research</h3>
        <p>
          I explored how to build space and emotion through effects this week.
          To make the sound design feel wide and immersive, I experimented with
          varying levels of reverb, delay, and layering and keeping the dry/wet
          balance lower at the start and opening it up as the visuals progress.
          I also experimented more with automation than I usually do, especially
          to make certain parts fade in or glitch out. Mastering has always been
          difficult for me, and I watched a few different videos to help me with
          it! One of them being
          <a href="https://www.youtube.com/watch?v=fZdlUiqiDoM">this video</a>
          which talks about different techniques to make audio spaces feel wider
        </p>

        <h3>Progress Report</h3>
        <p>
          This week I mainly focused on the completion of Assignment 2.1. I
          started by creating the atmosphere first by layering different
          horror-themed ambience to create the general structure
        </p>
        <img src="photos/week2/ambience.png" alt="" />
        <p>
          Then I added all the sound effects, including the wet sounds for the
          bursting tentacles (I used a variety of different slime sounds), the
          cinematic risers and faders, etc.
        </p>
        <img src="photos/week2/fx.png" alt="" />
        <p>
          After that I experimented with different odd and unique sounds to get
          a more interesting texture
        </p>
        <img src="photos/week2/unique.png" alt="" />
        <p>The finally just the static at the start.</p>
        <img src="photos/week2/static.png" alt="" />
        <p>
          After that I spent quite abit of time adding reverb and sending it
          through buses, and EQ shaping and effects to make the sound a bit
          wider a larger!
        </p>
        <p>
          Other than the Resonance project, I was also able to secure the spot
          to make sound design for one of my friends games! It is a pretty
          simple game, but it is a good introduction into make sound for games,
          as I have never tried that before. I will need to learn Unity and
          FMOD, and just interactive music in general.
        </p>
      </div>
    </details>

    <!-- ------------------------------------ WEEK 3 ---------------------------------------------- -->
    <details class="week" id="week-3">
      <summary>Week 3</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          As I can't attend class, it's pretty difficult to write a reflection
          on ideas raised in class, especially when there isn’t any official
          lecture, but I will try my best!
          <br />
          <br />
          The first class focuses on presentations and feedback for Assignment
          2.1. I showed a few of my family members I am with my project and
          asked their thoughts on it. They aren't sound designers and don't
          really think like them, but this is exactly why I thought their
          feedback was so good. They were able to tell me feedback based on a
          normal consumer level. For this project I generally was told that it
          was very low and that I tend to focus on lower sounds and frequencies,
          leaving the higher ones lacking. I didn't make use of the entire
          frequency spectrum. This made the sound seem a bit muddy or even
          lacking, and hard to make out specific parts. I think especially
          listening to my own work on speakers made this very clear, as I didn’t
          really notice when I was mixing it with headphones in.
          <br />
          <br />
          Another piece of feedback I got was that my mixing could have been
          better. The atmospheric sounds were a bit low and hard to hear, while
          the squelching noise was loud and overbearing, it was basically all
          they could hear. I think feedback like this is especially important,
          and will keep in mind for the future! I think I really need to invest
          in some speakers... It also made me realise how important it is to
          check a mix on different playback systems, what sounds balanced on
          headphones can feel completely different on speakers. This is
          something I’ll try and consciously do for all my future projects.
          <br />
          <br />
          Although, they did like the amount of layers I put in, they felt like
          it had good amounts of sound, was realistic, and they could make the
          connection between the visuals and the audio I chose. They also liked
          the atmosphere I was able to create, and they were particularly
          impressed with the sound design when the tentacles started exploding
          out of the planet. Both the positive and negative feedback is very
          important to me, so I was happy to receive detailed feedback from a
          regular, consumer perspective. It reinforced the idea that while
          technical skill is important, the audience’s emotional and intuitive
          response is ultimately what matters most.
          <br />
          <br />
          The second class had a guest lecturer, and I’m honestly so annoyed I
          missed it because the topics covered sound like they would have been
          incredibly useful. Since I wasn't there I will just talk about my own
          thoughts...
          <br />
          <br />
          I’ve always been a bit confused about the difference between sound
          editing and sound design. A lot of my own process involves editing and
          adding effects to audio from sound libraries, so does that still count
          as editing, or is it considered sound design? Does sound design only
          mean foley or creating audio entirely from scratch? It makes me wonder
          what actually defines a sound designer, especially when I’ve seen
          purists online who refuse to use sound libraries at all, and shame
          anyone who does. Personally, I think there are certain sounds that are
          just impractical or nearly impossible to record yourself, so using a
          library can be the smarter option. I mean, if it already exists, why
          not use it? But I do think people should at least try to build up
          their own sound repertoire so they don't have to rely on sound
          libraries forever.
          <br />
          <br />
          I also think that knowing how to make exactly what you're thinking is
          incredibly hard, but super rewarding once you are able to. As with all
          creative practices, you get the hang of it once you start doing it
          more, and being in this studio and having to make audio for visuals
          every week so far has actually shown a significant improvement in my
          skills, which I am both surprised and thankful for. Missing the
          lecture makes me want to spend some time researching the roles and
          workflows the lecturer discussed, because I can already see that
          understanding the boundary between design and editing could help me
          plan my projects more efficiently.
          <br />
          <br />
          This also made me think about the phenomenon of the Wilhelm scream,
          which is that infamous stock sound effect everyone recognises. When
          it’s used, it can snap the audience out of immersion because they
          immediately associate it with other films. I think that raises an
          interesting question about when familiarity adds charm or nostalgia
          versus when it becomes distracting. In this case, I can see how using
          sound libraries can be not ideal, especially for big blockbuster
          films. Like surely they could have filmed a guy screaming instead of
          choosing to use a stock sound? I mean they have such big budgets
          right? This makes me reflect on my own sound choices, maybe I should
          be more conscious of using highly recognisable sounds unless I’m
          intentionally going for humour.
          <br />
          <br />
          Anyways, the rest of the lecture content, things like EQ, editing
          concepts, layering techniques, emotional architecture, and more, all
          sound super interesting. I’d love to dive deeper into those topics, so
          if the lecturer presents again or if there’s an online recording
          somewhere, I’d definitely want to check it out. In the meantime, I
          will probably explore some online tutorials or breakdowns from
          professional sound editors to get a better grasp of these concepts, so
          that next time I’m working on a project, I can apply more deliberate
          choices in rhythm, layering, and tonal shaping.
        </p>

        <h3>Academic Research</h3>
        <p>
          This week I read Zwicker and Fastl's Psychoacoustics: Facts and Models
          to understand more about how frequency content affects how we perceive
          time and motion in sound. They talk about how removing higher
          frequencies can make things feel slower and heavier, which is exactly
          what I needed for the slow-motion sections of my project. It gave me
          the idea to use frequency filtering instead of pitch-shifting or
          time-stretching. It was nice to have theory backed reasonings for my
          work, as I did notice a significant difference by using the pitch
          filtering because it was exactly what I was aiming for.
          <br /><br />
          I also read Altmans Sound Theory, Sound Practice which kinda goes into
          how sound and image work together to make meaning. Although this made
          sense to me already and in my head I thought this was obvious, I
          started to think more intentionally about my design choices, and why I
          chose a specific pad sound. I realized I chose it because
          subconsciously I wanted the pad to build up in the same way that the
          cube does visually. I connected this with the pitch frequency
          filtering, where the sound slowly regains its higher frequencies and
          the audience will get reinforcement that the video is progressing, and
          just gives it structure overall.
          <br /><br />
          Holman's Sound for Film and Television was also another useful text
          for this week. He talks about matching the texture of sound to the
          visuals, which made me change my EQ choices for the Lego building
          sound. I knew that the Lego sound felt out of place, but with EQ I was
          able to get it to feel shinier and cleaner which matches the visuals
          aesthetics way more. I did this by boosting the higher end, lowering
          the bottom and keeping the mids relatively the same to still maintain
          that tactile feeling of the original recording!
        </p>

        <h3>Artistic Research</h3>
        <p>
          I was rewatching a few old Pixar films recently and one of them
          particularly caught my attention sound wise. Wall-E's different sounds
          and expressions are made by using everyday objects to make sound, yet
          still felt so emotional and believable and had this weight to it. It
          felt authentic. I was inspired by this, as I thought it was so
          impressive how this sound was made and edited. It was what gave me the
          idea to find everyday objects for this weeks project, which ended up
          being Lego. It is a familiar and nostalgic sound and while its not a
          direct match for the sound I imaged for the cube, I could process it
          but still keep that tactile identity.
          <br /><br />
          I also listened to Royji Ikeda, who makes super minimalist and precise
          tones to make his sound. It's very clean and he uses a lot of control
          and timing to make his music (though I would just call it sounds
          rather than music). This is what made me want to try limiting the
          amount of sounds I can use, to try getting the full potential out of
          the sounds I already have in the project, by using control and timing.
          Ikeda showed me that simplicity can be just as powerful and impactful
          as complexity, and I really wanted to experiment with that in my
          project this week.
          <br /><br />
        </p>

        <h3>Technical Research</h3>
        <p>
          This week I mainly focused on how to make glassy and shimmery sounds
          from scratch, as I tend to rely on a lot of sound libraries for it.
          Although there is nothing wrong with using sound libraries and
          manipulating the sound, I thought it would be best to at least learn
          how to make some so I could build my own sound effect library. I
          followed this
          <a
            href="https://www.youtube.com/watch?v=CEZHfQOqQxQ&ab_channel=UnderdogElectronicMusicSchool"
            >YouTube video</a
          >
          which uses FM synthesis to make those glassy sounds. He is a very good
          teacher, calm and explains himself well, so I will be looking more
          into his other videos in the future. Although he used an Ableton
          feature that I don't have, I found the skills to be transferrable to
          other budget options and plugins, as he explains why he does each
          step, and even showing the difference between each parameter in the
          different effects he uses. It was a super informative video and I was
          able to make a few sounds I liked! <br /><br />
          I also watched
          <a href="https://www.youtube.com/watch?v=UQy7VHm-Ucg">this video</a>
          which is a tutorial on how the PaulXStretch plugin works. It goes
          super in depth and explained all the features and I can't believe the
          plug in is free. Although I ended up having some technical troubles
          and couldn't use it for this weeks projects, I am excited to fix it
          and use it in the future! Especially the ability to change different
          harmonics and use it in conjuction with other effects would make for
          really good experimenting.
        </p>

        <h3>Progress Report</h3>
        <p>
          I had a lot of projects to work on this week! I had a bunch of people
          reach out to me to do the sound design for their projects but
          unfortunately I wasn't able to do all of them, even though they were
          all such interesting concepts. One of the projects I chose to work on
          was "The Reconnect". Caroline, the animator, sent me her draft
          animatic, as well as a sound design brief and the project concept. I
          really appreciated how organized and professional the documents she
          gave me was, it was super helpful to decide what I wanted to do for
          her project, while bringing her vision to life. She gave me a small
          part of her animatic that was confirmed to stay the same, so I worked
          on that scene.
        </p>
        <p>
          I first started by making the ambience of the scene, like I usually
          do. I layered a few different textures to make the structure of the
          scene. Though it was pretty hard because it was a pretty small scene,
          but I'm sure when I work on the full thing, I'll be able to transition
          between sounds better, without sounding too abrupt.
        </p>
        <img src="photos/week3/reconnect2.png" alt="" />
        <p>Then I worked on the diegetic sound:</p>
        <img src="photos/week3/reconnect3.png" alt="" />
        <p>
          Then worked on the non-diegetic sound, and transitional sounds and
          wooshes:
        </p>
        <img src="photos/week3/reconnect1.png" alt="" />
        <p>
          And that was basically done for the scene! Again, it was pretty short
          and I kept the narration that was in the original animatic (which is
          why it might sound bad in terms of the mix, because the narration was
          also a draft), but I am happy with the general idea, and so was
          Caroline. She mentioned some changes when she finalizes the animation
          but it is a good start! You can watch the draft
          <a href="https://youtu.be/UgO7CwLyiRE">here</a>!
        </p>
        <p>
          Then I also worked (and finished) my Assignment 2.2 as I am busy next
          week and won't have time to do it! I first began by making my own pad
          sound using the tutorial I showed you earlier. I used his tip of
          turning the midi file into an audio file and used that to make all the
          changes, and added it into my personal sound library.
        </p>
        <img src="photos/week3/own.png" alt="" />
        <p>
          I then experimented with grain delay, using the pitch parameter to try
          and simulate the slow motion effect:
        </p>
        <img src="photos/week3/graindelay.png" alt="" />
        <p>
          I wasn't a fan of this as I wrote on my report, and decided to try
          using the PaulXStretch plugin:
        </p>
        <img src="photos/week3/paulstretch.png" alt="" />
        <p>
          But again, wasn't a fan and there was a steep learning curve and
          technical difficulties. I then decided to use frequencies filtering
          instead, which I was a fan of!:
        </p>
        <img src="photos/week3/padauto.png" alt="" />
        <p>
          It sounded exactly like I wanted. And then I did it for the lego
          building sound as well, with less of a sweep:
        </p>
        <img src="photos/week3/legoauto.png" alt="" />
        <p>
          Then it was just a matter of finishing touches! I added the sparkles
          that go throughout the entire video, but used volume automation so it
          was more prominent in the later half of the video:
        </p>
        <img src="photos/week3/sparkle.png" alt="" />
        <p>
          And that was done for AV2.2! I just had to write the report. But other
          than that, I also decided to use one of my old song projects for the
          music video I will do for this semester. Although I haven't 100%
          decided it will be a music video, I was also thinking of doing a light
          show for the Capitol Theatre! Which I thought would be cool. Anyways I
          went through a bunch of my old guitar files, and found this one I
          liked, where it was in the shoegaze genre, and I added some lead
          guitar over it and messed with the effects a bit, as well as adding
          the much needed drums. Although I am not a drummer and had to MIDI the
          entire thing, when I get back to Australia I'll probably use real
          drums and fix up the guitar parts, as well as add more instruments.
          You can watch the WIP of the song
          <a href="https://youtu.be/6MhdX7PVxWc">here</a>. I chose that song
          because it's very atmospheric, but still incorporates live instruments
          so it is the best of both worlds! (and I am a huge shoegaze fan)
        </p>
      </div>
    </details>

    <!-- ------------------------------------ WEEK 4 ---------------------------------------------- -->

    <details class="week" id="week-4">
      <summary>Week 4</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          This weeks lesson was about giving feedback to your peers about
          Assignment 2.2. Since once again I am away, I've decided to ask the
          people around me for feedback! Thankfully this is the last lesson I am
          away since next week there's no classes! The advice I got last week
          was actually extremely helpful in learning on what other people
          typically hear in a consumer standpoint, it helped me inform my
          decisions for this project.
          <br />
          <br />
          The main critique I had for my sound design was about the foley that I
          used for the cube-builing sequences and that it didn't feel as
          convincing as it could have been. They mentioned that it felt too
          clean and didn't match too much with the visuals. I realized that this
          probably happened because I relied too much on just the one sound
          layer, instead of using multiple diffrent textures. I usually do like
          to stack a bunch of effects and layers to achieve a sound, so I'm not
          sure why I decided not to do it here! Maybe because I was too focused
          in matching the clean visuals, and the fact I tried to impose a
          challenge on myself in using minimal layers. I think doing this lost a
          lot of weight into the sound that could have made the foley more
          believable. But now, I can actively use more layers on my next project
          (sourcing a variety of different sounds) and then layering them to
          create more depth and realism!
          <br />
          <br />
          The other criticism I received was that the atmosphere wasn't as
          immersive as my previous project. Even though there was that challenge
          of the minimal layers, I do think the atmospheric sounds and ambience
          was a bit low, and you could barely hear it once the layers started to
          build up. I definitely spent more time building layers and acheiving
          depth compared to this work, which is probably why they felt there was
          a lack of atmosphere in this project. Next time, I would like to be
          more intentional about the spatial audio, and making sure the
          environment feels alive before I start working on the diegetic sound!
          <br />
          <br />
          However, the consensus was that the slow motion sections felt great,
          they could feel that it was meant to be slow motion. It felt natural
          and well-timed, and they particularly liked how all the aspects felt
          like they were slowing dowm, and helped reinforce the visuals. I put a
          lot of focus into getting the feeling of slow motion down, and getting
          all the automation to match up to the visuals and all the sound, so I
          was very glad and happy to receive that feedback! Very encouraging.
          The changes between different motion speeds flowed in a way that kept
          the pacing smooth, which tells me that my use of automation has gotten
          much better! I'd like to experiment a bit more on the gradual blends
          and transitional elements to really nail it for my future projects!
          <br />
          <br />
          Overall this feedback made me realize I tend to prioritize certain
          aspects and because of that, potentially can overlook others. I'm
          happy with the parts I spent a lot of time on, but I know I really
          need to push my foley design and environmental layering if I want to
          improve my design further!
        </p>
        <h3>Academic Research</h3>
        <p>
          This week I researched a lot on how to create horror ambiences, and
          what can cause viewers to be scared just through audio alone, as well
          as how audio can enhance visuals and imply something is there to keep
          viewers on the edge of their seat
          <br />
          <br />
          Blumstein, Davitan and Kaye discuss how harsh, non-linear sounds can
          trigger instinctive threat responses in their article, 'Do film
          soundtracks contain nonlinear analogues to influence emotion?'. This
          can be sudden distortion, bursts of noise, unpredicatable modulation,
          etc. because they can resemble animal distress calls. I could use this
          idea by adding these short bursts of sound and effects at moments
          where I want to create sudden tension. Using this technique would give
          me a more natural way to make an audience feel unsettled without
          solely relying on visuals jumpscares.
          <br />
          <br />
          Another interesting article I read was by Menninghaus 'The
          Distancing-EMbracing model of the enjoyment of negative emotions in
          art reception'. It looks about how inharmonic or detuned sounds create
          a sense of unease because it disrputs the harmonic balance that we
          expect. This would be interesting to apply into my horror/triller
          ambiences that I am creating by layering slightly out of tuen drones
          or pads underneath other layers to make a sense of unease in my
          projects. It would let a scene feel tense even if nothing dramatic is
          happening visually, which is important for horror ambiences.
          <br />
          <br />
          A lot of the research I do on ambiences and music typically involve
          sound and making it. But I think this book by ZhouI read is
          particilarly interesting ebcause it talks about the absence of sound
          and its effects ('Effects of silence on emotion response to sound').
          He explains how silence and sudden changes in dynamic can actually
          heighten emotional impact and reactons to sound. I think I can use
          this in my own projects by adding short, deliberate pauses before a
          loud or important sound effect , which can bring attention to it and
          heighten its impact. It would make those moments stand out more,
          especially in suspenseful scenes.
        </p>
        <h3>Artistic Research</h3>
        <p>
          Because I've been so focused on horror this week, I went back to the
          Silent Hill series, a famous horror game known for its creepy
          atmosphere. Akira Yamaoka was the sound designer for the franchise,
          and he tends to blend industrial noise, detuned instruments and
          minimal melodic elements to create spaces that feel haunting. Since
          Silent Hill is a game, he uses looping textures that evolve slowly,
          making the player feel trapped in the emotional state he creates. I
          could use this technique in my future projects, and even the
          animations I am involved in this semester by creating subtle
          variations between each scene to sustain tension in scenes where not a
          lot of dramatic events happen. However this would be especially useful
          in long sequences where the user explores a space and they tend to get
          lost and immersed, that they forget about the sound.
          <br />
          <br />
          Another game that is pretty famous for its horror sound design is
          Resivent Evil. Shusaku Uchiyama relies heavily on lower drowns, tight
          reverb and metallic sounds to manipulate the players feeling of space,
          making them often feel ecnlosed and claustrophobic. I love this game
          series and I genuinely feel scared while playing the game, especially
          being hyper aware of my surroundings and getting scared over things
          that wouldn't scare me usually. I feel like I could adapt this into my
          own work by shaping the reverb and adding lower frequencies to make
          the space feel smaller and constricted, to try and make the viewers
          feel the same as I do when I play Resident Evil. I think using sharp
          high pitched stingers can also make the listener snap and pay
          attention to key moments if I use them alongside the low drones.
          <br />
          <br />
          Other than games, I also found this sound designer and composer called
          Lustmord, who specializes in making ambient music that feature low
          drones, reverb and little high frequency details. This skewed
          frequency spectrum can evoke a sense of oppressive vast emptiness. His
          music is kind of minimalist, which proves that horror sound design
          doesn't need to be super busy or full of layers to be effective, it
          comes from scale and patience and building (which I could probably use
          in my projects as I tend to just stack layers and hope it works). I
          could use his philopsophy to try to strip back my soundscapes and
          focus on depth and detail in a few elements to make the atmosphere
        </p>
        <h3>Technical Research</h3>
        <p>
          This week I watched
          <a href="https://www.youtube.com/watch?v=U7wkq_s2t4M"
            >How to Design Dark and Scary Sounds</a
          >
          which went through a bunch of techniques on, well, how to design dark
          and scary sounds! It went through backmasking, backwards reverb,
          backwards talk, the importance of slowing things down and combining
          all of these. I liked this tutorial because it shows how different you
          can make sounds just by transforming existing recordings using effects
          and such, rather than trying to make a purely scary sound.
          Experimenting with my own sounds and seeing what I can create with
          them is an important part of sound design and I want to try
          experimenting with this in the projects this semester! I think it'd be
          cool to have backwards talk for an easter egg in one of the
          animations.
          <br />
          <br />
          I also watched
          <a href="https://www.youtube.com/watch?v=8QlWUGtB_9w"
            >How to Sound Design Horror Atmospheres using Vital</a
          >
          which was basically a deep dive into building horror ambiences from
          the very beginning. It also was kind of a tutorial on how to use Vital
          as I am still not 100% comfortable using it. Anyways, it went step by
          step on how to set up the oscillators and effects and adding pitch
          modulation and movement. It also went through a bit of basic music
          theory, specifically using minor seconds to create dissonance and also
          showed how to create intros, risers and just evolving atmospheres in
          general. This was super helpful because it explained what to do, but
          also why were doing each step so I could make my own atmospheres using
          the same basics. Even though it was specific to Vital, I can
          definitely use this information in other synths or plugins!
        </p>
        <h3>Progress Report</h3>
        <p>
          This week was when I was the most busy overseas, so I didn't get to
          work as much on my projects as other weeks(which is why a lot of my
          assignments were done super early if you noticed!), but I still tried
          to do a few.
          <br />
          <br />
          I mainly tried to work on things that I could do without external
          equipment (as I usually use a MIDI keyboard, and I don't have access
          to a professional recorder). I worked on the song I will use for the
          music video (although plans have changed and I'm not sure if my
          videographer has time, so I might do a lighting show alongside my
          song) and fixed up a bit of the drums. I used the free kits in the
          Steven Slate Drum's pack and it sounds way better than the default in
          Ableton. Though some of the snares were a bit off so I had to go in
          and manually change the different MIDI notes which was a bit tedious,
          but I am very happy with how it sounds so far. I also used Shreddage
          to add a bit of bass and other guitar parts that I would like to try
          once I'm back at home with my instruments. I also started to
          experiment with lyrics (this is what I was dreading) and melody, but
          haven't found anything that particularly stuck to me.
          <br />
          <br />
          <img src="photos/week4/1.png" alt="" />
          I did the same with some piano synths to create a kind of wall of
          sound. I used the video mentioned in the technical research to really
          help me with the order of effects and such. I'm very excited to work
          on this with real instruments (especially real drums!)
          <br />
          <br />
          This week had a lot of focusing on planning the semester, especially
          how I will organize my time once I am back.
          <br />
          <br />
          I had a call with Tara, the animator of alskdn, as well as Maria (a
          sound designer from our class), as we are both working on this project
          together. We just talked about what her vision is for the sound
          design, and what we could achieve based on that. She was very
          understanding and very helpful, gave us a timeline of when things will
          be done, what she expected of each scene, but also trusts us and gave
          us a lot of room to be creative and do what we want to make the sound
          match the visuals. It's hard to work on specific sounds as the
          animatic isn't confirmed 100% yet and is still subject to change, but
          she said she will be done soon so we can start as soon as possible!
          She also put us in contact with the voice actors, so we are able to
          communicate directly in case certain sounds need to be rerecorded, I
          am happy to be working with someone who is on top of everything and is
          thinking ahead!
          <br />
          <br />
          The other animation, 'The Reconnect', that I am also working on, I
          also had a proper chat with animator on what she wanted the sound
          design to achieve. She was more loose with the descriptions, and
          instead wrote more about what she wants each scene to feel like. I
          think this will be good experience on creating my own visions based on
          client's requirements on the atmosphere and end product, while the
          other project will be good experience on achieving balance betweenthe
          specifics of what the client wants for each scene, versus what I
          believe as a sound designer. I am very grateful to both for being very
          flexible and understanding, while also giving guidance, I am very
          excited to be working with them! At the time of writing this, she
          actually reached out to me saying the first 10 seconds of the
          animation is fully complete so I will be working on that next week!
          <br />
          <br />
          Because both of these animations are very horror, thriller and tension
          based, I started to resarch a lot with creating ambiences, since I can
          use these as layering materials for any of these projects (and even
          future ones!). What I learnt can be seen in the technical research
          section! This was my favorite part as I was able to create a lot of
          audio clips that I can use in the projects, maybe with a bit of
          editing to fit the actual scene, but overall I am very happy with the
          progress. I have a lot to work on once I am back next week!
          <br />
          <br />
          I also had a call with the game developers of 'Fired Before Hired' and
          what sound design and foley they expected of me. This project is
          heavily reliant on realistic sounds, like whooshing of swords,
          furniture being broken and torn, etc. so I really get to work on my
          audio recording skills (which honestly need a lot of work...!). I am
          nervous to record, but also excited because I know its a skill that is
          necessary and would like to get better at. I was also asked to make
          the menu music, and kind of like office/elevator music. They said they
          weren't sure of what kind of vibe or genre they are going for, so they
          want me to make a small snippet of different ones, like 8bit,
          electronic, real instruments, etc. This makes it kind of difficult,
          but hopefully I can only make a 5-10 second clip so they know. Or I
          was thinking of using MIDI, so I am able to easily change the
          instruments so they can decide, and then I can further refine it.
          <br />
          <br />
          With this information I made a general timeline of when I want to have
          things done, but the general timeline is as follows:
          <br />
          21st-24th = Fired Before Hired menu music clips, figure out all parts
          of the song
          <br />
          25th-31st = Begin working on the animations (this is when both
          animators are expecting to finish the final draft so we know the
          timing of each scene), especially using the pod alongside Maria to get
          our ideas down, start officially producing song
          <br />
          1st-7th = Finishing producing song, as well as mixing and mastering,
          record and finish the sound bits for Fired Before Hired, continue to
          work on animations as scenes gets finished
          <br />
          8th-14th = Figure out how to work sound in Unity, start working on the
          level music for Fired Before Hired, continue to work on animations as
          scenes gets finished
          <br />
          <br />
          This is just the general plan for the next few weeks, I am very aware
          that it is a lot per week, and other classes may take priortity in
          certain weeks. This is just a general guideline of the best case
          scenario and finishing early, which I know won't 100% happen. But
          having a guide of what I want to do and pushing myself helps me to do
          more work! Anyways I am definitely savouring my last week of being
          away before all my assignments starts getting due soon....
          <br />
          <br />
        </p>
      </div>
    </details>

    <!-- ------------------------------------ WEEK 5 ---------------------------------------------- -->

    <details class="week" id="week-5">
      <summary>Week 5</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          There was no class this week so nothing I can write for in class
          learning, but I am writing more reflective writing in the research
          section to make up for it!
        </p>
        <h3>Academic Research</h3>
        <p>
          I did some research in collaboration in creative audio communities,
          and found this article by Calefato, Lanubile, Novielli and Valetto,
          titled "Collaboration success factors in an online music community".
          It talks about successfull collaboration depends on momentum,
          recognition, and individual contributions for the project. This really
          helped me figure out a way to interact with the people I am
          collaborating with, changing my mindset into a more professional one
          and some tips on how to make the collaboration successful. The article
          made me consider how my sound design interacts with their creative
          vision, rather than just being a seperate entity. Since the
          collaborative works I am working on are majorly for someone elses
          creative visual work, it is important to keep a line of communication
          open, while also figuring out on creating a balance of what the
          collaborator wants, as well as putting my own creative vision into the
          work. I also found that receiving feedback and adjusting drafts was
          not only about fixing mistakes, but also creating cintinuity with the
          animators intention for the work. I also noted that some collaborative
          practices could be helpful in my own solo projects, for example,
          creating a variety of drafts to see which I like better, rather than
          continuously working on the same project to see if I'll end up liking
          it. The article really helped me develop this mindset of openness and
          responsiveness that could definitely imrpove both group and individual
          projects.
          <br />
          <br />
          I read another article titled "Footsteps with character: The art and
          craft of Foley" written by Wright. It describes Foley as not just a
          technical task to record sounds, but also a craft where sound
          designers have the chance to add character and intention into ordinary
          noises. This information will greatly help me in the future when I do
          more intensive foley tasks. I have taken foley as just a task that I
          needed to tick off before I start doing actual sound design work, but
          this shifted my mindset into adding more intention with my recording.
          I could experiment with textures and performance to transform regular
          sounds into something that would fit hte emotional tone of the
          project.
          <br />
          <br />
          The last article I read is by Sonnenschein, "Sound design: The
          expressive power of music, voice and sound effects in cinema". It
          talks more deeply into creating atmosphere, and especially reverb and
          other spacial effects can play a crucial role in establishing a
          storytelling place and guides audience's emotional and perceptual
          focus. This directly connects to by attempt to design the atmosphere
          of a church which is a setting in one of the animations I am working
          on. In my draft, I leaned heavily of reverb to create a sense of
          scale, but after reading this, I realize I might have prioritized size
          over clarify of my work. Sonnenschein'd discussion of how sound
          environments shoould evolve dynamically made me think of reverb as
          something I should modulate and change across scenes, which I will
          definitely keep in mind for the future scenes of the animation.
          <br />
          <br />
        </p>
        <h3>Artistic Research</h3>
        <p>
          Ben Burtt, who is best known for his work in Star Wars, is a foley
          artist that I looked into this week. He invented the sounds which have
          become icons in culture, and he approached it by using unexpected
          sources for sound. He shows that sound design is about creativity, not
          just accuract. I realized I could adopt a similar mindset for my own
          foley work. For example, instead of trying to find the most accurate
          footstep in the animation I'm working, I could isntead try to find a
          sound that could convey the weight and unease and tension in that
          moment. Burtt;s practive reminds me that emotional believability is
          also an important factor to consider, rather than just realism. I want
          to explore more freely with Foley in my upcoming projects so they can
          carry the sound I want it to express.
          <br />
          <br />
          Chris Watson is another foley artist that mainly captures amazing
          natural soundscapes with amazing detail and is often used in nature
          documentaries. His work shows how sound can transport a listener into
          the place and immerse them in its atmosphere, even without visuals.
          This pushes me to think of environmental sounds not just as background
          noise, but the backbone of the scene. I realize I should listen and
          put more intention in the ambience that I create, experimenting with
          layers of tone, resonance and silence. I want to to make a mix that
          tries to capture a living environment, and shape how the audience can
          feel inside that space.
          <br />
          <br />
          The last artist I looekd into was Suzanne Ciani, who makes electronic
          soundscapes using synthesizers to design immersive textures! She
          created electronic sounds for Atari and Coca Cola ads and was a
          pioneer with proving how synthetic audio could feel tactile and human.
          I really like her ability to make electronic tones sound like they
          have so much character and movement. I would like to see how I could
          experiment with this in the future, maybe in the game I am designing
          the sound for.
          <br />
          <br />
        </p>
        <h3>Technical Research</h3>
        <p>
          This week I just researched how to record good foley, taking
          inspiration from professional foley artists.
          <a href="https://www.youtube.com/watch?v=amNxmSVYc34">This</a> video
          explores how professionals get ready and set up for recording, with
          most of the work before the actual recording date. Whenever I look at
          doing foley recordings I always just grab a microphone and look at the
          list of things I need, which gets the job done, but I noticed not as
          well as I hoped. From this video I saw that they have a specific
          recording schedule, packed with information like what props will be
          needed, the duration needed, where the recording will be held, etc. In
          the future I want to be more organized with my shooting schedule,
          similar to this so I know what exactly I need without just winging it.
          <br />
          <br />
          For the actual recording they had a few helpful tips that I will use
          in my future foley recording sessions. I tend to just make generic
          sounds and manipulate it to fit the scene later, especially if it's
          something generic like clothes rustling or such, but I see the benefit
          in actually recording while watching the visuals. It seems like such a
          simple thing, but because I don't have a studio and I tend to record
          everything myself, I find it difficult to put a screen down where I
          can see the visuals of what I'm recording, but still holding up the
          microphone (since I don't own a stand) and also making the sound
          needed. In the future I will probably ask for some help, or at least
          borrow a mic stand to make it easier on myself.
          <br />
          <br />
          The video also talks a lot about how certain sounds can be scarily
          close to other sounds. The famous example of pan frying bacon sounding
          like rain is a prime example of this. I want to be more creative with
          my ideas, and not be such a purist when it comes to sounds, as I tend
          to like recording the exact same sound that is in the film, even if
          there could be an easier version.
        </p>
        <h3>Progress Report</h3>
        <p>
          I was very busy this week again with my flight and then had a trip to
          the emergency room (I am fine!) but I was able to get a draft down for
          the animation 'The Reconnect'. Caroline the animator sent me the first
          scene of her animation and sent me a little brief as well as what
          sounds she imagined for that scene.
          <br />
          <br />
          She mentioned footsteps playing a main role in the animation, so I
          started with that. It was a bit tedious to get the timing right but I
          got it in the end. I layered a clip of wood creaking, as well as
          isolated footsteps so the individual footsteps would be a bit clearer
          and wouldn't get drowned in the creaking noise. Since the setting of
          this scene was in a church, I did some pretty spacious reverb to get
          that wide sound, and put the wetness lower for the isolated footsteps,
          again to be a bit more clear. Since there were 2 pairs of footsteps, I
          made the closer ones with a bit less space and delay, so the listeners
          can differentiate them, as well as they are in a more walled off area
          than the other character.
          <br />
          <br />
          <img src="photos/week5/1.png" alt="" />
          <br />
          <br />
          I then went and layered a few horror ambiences, trying to focus on
          having the full frequency range in the scene. I did some low humming
          drones, a creepy airy atmosphere sound, as well as a high pitched
          chimes to add to that creepy atmosphere. I also tried to experiment
          with a sample of a choir singing, and pitching that around, but I'm
          not sure if that vision is what the animator wanted, so I've sent her
          varying sound design works to see which one she likes the best.
          <br />
          <br />
          <img src="photos/week5/2.png" alt="" />
          <br />
          <br />
          Finally I added some finishing touches! I added a heartbeat which I
          automated to get increasing louder and faster to help build tension. I
          also added a riser near the end to accompany the buildup of the rising
          heartbeat. Other than that, I added a few shaky breaths of both the
          person dying at the start, as well as another shaky breath when the
          girl sees the scene and gets scared.
          <br />
          <br />
          You can watch the first draft
          <a href="https://youtu.be/bs8I764QiyE">here</a>! I think a bit of the
          ambience is lacking, I think I could have made it a bit more
          expansive. Caroline mentioned she wanted it to be "witchy" but I am
          not sure how to achieve that so I will be sure to ask her then add it
          to the second draft! I'm excited to hear the feedback for this draft.
        </p>
      </div>
    </details>

    <!-- ------------------------------------ WEEK 6 ---------------------------------------------- -->

    <details class="week" id="week-6">
      <summary>Week 6</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          This week in class we analysed the opening sequence of A Bug’s Life in
          three different times, one with effects only, music only, and then the
          combined track. Watching the film with only effects highlighted just
          how minimal yet purposeful the sound design is. The crickets, wind,
          and water effects built a naturalistic atmosphere, while footsteps
          were much heavier than I initially expected, maybe I expected it to be
          lighter because they were ants! That weight gave the characters a
          tangible presence and energy within the scene. I actually was shocked
          with how little effects were used. I alsways assumed there was more,
          but maybe because it is a children's animated film, it would have less
          than something recorded with real actors and such. I noticed how many
          environmental sounds faded away whenever the characters returned to
          focus, suggesting that hierarchy in the mix is used deliberately to
          guide attention.
          <br />
          <br />
          When listening to the music track separately, it revealed how much it
          shapes the emotional soundscape. There were stings placed on small
          visual actions, like the bass note hitting when the ant is struck by a
          falling fruit. At other times the score helped the flow of the
          narrative, for example when everything is calm, the melody was light
          and playful, but when problems emerged the bass slowed and thickened,
          and the music grew louder to match the threatening buzz of a chainsaw.
          <br />
          <br />
          Hearing both together showed how layers of sound work across the
          frequency spectrum. Music filled the higher registers while the foley
          sat lower, producing a more complete sense of space. What stood out
          most to me was how much character movement can be conveyed through
          sound alone, like their clumsiness, confidence, and awkwardness were
          all suggested simply by timing and emphasis. The exercise reminded me
          that sound is not just accompaniment to visuals, but a central force
          that defines mood, guides attention, and can even reshape how we
          interpret characters and their behaviors.
          <br />
          <br />
        </p>
        <h3>Academic Research</h3>
        <p>
          I read an article by Philipp Schmerheim and Tobias Kurwinkel titled
          "Sound Design in Children’s Film". It explains how sound in children’s
          media can play a crucial role in guiding perception, since younger
          audiences often rely on audio cues more than visual details to
          understand what is happening in scenes. The article pointed out how
          important it is to create a hierarchy of sounds so that key actions
          are easy to follow without overwhelming the listener. This perspective
          changed how I think about my own work, because I usually focus on
          adding detail and texture, but this showed me that sometimes clarity
          and restraint are more powerful, especially when designing for
          children. I can apply this to my own work even if the content I'm
          producing isn't really meant for children. I can do this by being more
          deliberate about which sounds need to be in the foreground, and which
          can fade back, ensuring that the main story always comes through
          clearly.
          <br />
          <br />
          I also read a scholarly reflection on sound design in contemporary
          animated films such as Coraline, The Incredibles and Bolt. The article
          compared how each film tailored its approach to sound design to suit
          its genre and mood. Coraline used minimal soundscapes to create a
          strange and unsettling atmosphere, while the other two relied on rich,
          layered mixes to heighten the action and energy in scenes. What stood
          out to me was the emphasis on clarity across all styles. This reminded
          me that sound design should never be about filling space, but about
          supporting the narrative with intention. I found this inspiring
          because it encouraged me to think more flexibly, and allowing a
          minimal approach to make a scene more effective, while at other times
          layering multiple sounds can build intensity. In both cases, clarity
          should remain the goal, and I want to carry that mindset into my
          future projects, especially with my tendency to add too many sounds.
        </p>
        <h3>Artistic Research</h3>
        <p>
          For my artistic research, I decided to look into kids animated films
          again, and I looked into the work of Randy Thom, who has done
          extensive sound design for animated films including The Incredibles
          and How to Train Your Dragon (which is one of my favorite animated
          films of all time). Thom talks about how children’s films often
          require a very careful balance between realism and exaggeration
          assounds need to feel believable enough to anchor the world, but they
          also have to be expressive and playful. For example, he often layers
          real recordings with stylized or exaggerated effects to give everyday
          actions more personality I can use this for my own work by designing
          sound (especially if I ever do sound design for children's media) by
          finding the right degree of clarity and character, rather than aiming
          for complete realism. It made me realise that when I work on projects
          with younger audiences in mind, and even older audiences, I should
          think about sound as a way of storytelling on its own, where even
          small effects can reveal emotion or intention.
          <br />
          <br />
          I also decided to look into horror sound designers, and I found Gary
          Rydstrom, who has worked on films like Jurassic Park and A Quiet
          Place. Rydstrom describes horror sound design as being less about what
          is heard and more about what is implied through silences, distant
          rumbles, or subtle textures that can create more fear than overtly
          loud sounds. He also notes how horror often uses low frequencies and
          dynamic shifts in volume to keep audiences on edge, exploiting the
          body’s physical reactions to sound. This made me reflect on how
          different the goals of sound design can be across genres like where
          children’s films need clarity and guidance, horror thrives on
          ambiguity and tension. For my own projects, it pushes me to think
          about silence and restraint as creative tools, and not just the sounds
          themselves. By considering how audiences are meant to feel, I can
          adapt my design strategies to match the emotional core of the genre.
        </p>
        <h3>Technical Research</h3>
        <p>
          This week I watched a tutorial on the fundamentals of EQ and how it
          can be applied in sound design. The video explained how EQ isn't
          really just about boosting or cutting frequencies to make something
          sound better but about carving out space so each element in a mix can
          be heard clearly. It broke down the frequency spectrum into ranges,
          like sub-bass, low mids, high mids, and highs, and showed what
          typically lives in each area. It kind of reminded me when I created
          the sound design for Shelves by Gina Moore, when I was working with
          orchestra. All the different instruments focus on different frequency
          ranges to create this full sound! I just thought that was pretty cool
          and linked together something I've done before to something I focused
          learning this week.
          <br />
          <br />
          I found it especially useful when he demonstrated how too much low-mid
          energy can make a sound muddy, while carefully reducing those
          frequencies can suddenly make a mix feel clearer. Reflecting on this,
          I realised how often I tend to layer sounds without thinking about how
          they overlap sonically, which can cause clutter. EQ gives me the
          technical ability to separate those layers, making each one
          purposeful. In my own projects, I definitely can see myself using EQ
          to sculpt sounds to sit in their own space and highlighting the
          qualities that make them expressive. I will definitely try this next
          week for The Hollow Child draft.
        </p>
        <h3>Progress Report</h3>
        <p>
          This week I mainly did work on The Hollow Child animation! I had a
          chat with the animator Tara in person, and we went scene by scene of
          what her plans were, what she expected and gave us a timeline to have
          the draft done next week! Which was kind of really quick for me which
          is why this week I mainly only did this project.
          <br />
          <br />
          Tara had hired voice actors for the different characters and sent us
          the voice recordings for it, so the first thing I did was do the
          timing for all the laughs and sounds for the ghost girl:
          <br />
          <br />
          <img src="photos/week6/girl.png" alt="" />
          <br />
          <br />
          There wasn't any actual dialogue or speaking, but there was a lot of
          laughing and random sounds, so I really focused on making sure I
          didn't miss anything. I then did the same for the werewolf:
          <br />
          <br />
          <img src="photos/week6/werewolf2.png" alt="" />
          <br />
          <br />
          It was pretty difficult in general because obviously the animation
          isn't finished, so I don't think the timing will be correct, but it is
          an easy fix and just a matter of moving the timings around once the
          animation is finished! These steps took me a surprisingly long time,
          especially listening to the MINUTES of each characters' different
          sounds and organizing them based on what it sounded like to me/what I
          will use it for, and then trying to find ones that fit the scene. I
          would have liked for more sounds from the werewolf voice actor, so I
          might ask if that is possible for the final sound design.
          <br />
          <br />
          I then worked on the intro, trying my best to create a lonely
          atmosphere, and focusing on the breaths of the werewolf, as well as
          the wind. I used reverb to achieve this:
          <br />
          <br />
          <img src="photos/week6/reverb.png" alt="" />
          <br />
          <br />
          And I automated this reverb so when the camera zoomed out on the
          werewolf laying down, the size and dry/wet ratio would go higher to
          get that sense of vastness. I also made it so at the start, the breath
          and sounds were mono, and as the reverb automates to get larger, the
          stereo width gets wider!
          <br />
          <br />
          <img src="photos/week6/automation.png" alt="" />
          <br />
          <br />
          I then made a reverb bus, and put all my tracks to have varying levels
          of reverb, including the girl's and werewolf's sounds for later in the
          animation. After this I also added some diegetic sound like crows, and
          birds chirping, as well as wind and grass/leaves rustling. This set me
          up to create the ambience and non-diegetic sounds next week!
          <br />
          <br />
          Other than working on The Hollow Child, I also followed up with my
          other projects, and am waiting to get more scenes to do sound design
          for The Reconnect! The animator said she would get them to me by the
          end of the week! I also started to master and mix some of my song that
          I made, as well as finalized the structure since I wasn't a fan of it
          before! I want to add a guitar solo to it!
        </p>
      </div>
    </details>

    <!-- ------------------------------------ WEEK 7 ---------------------------------------------- -->

    <details class="week" id="break-week">
      <summary>Week 7</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>...</p>
        <h3>Academic Research</h3>
        <p>...</p>
        <h3>Artistic Research</h3>
        <p>...</p>
        <h3>Technical Research</h3>
        <p>...</p>
        <h3>Progress Report</h3>
        <p>
          This week included a lot because I'm also counting the break week! I
          was also thinking of dropping the music video project because things
          have come up unexpectedly and I still believe that I can hit the 100
          hour mark even without it, considering how much work I've done so far.
          This was a mix between the videographer pulling out, and me being
          unable to do a Pharos project because of how late I was given notice.
          If I have time, I might do the music video myself since I already the
          song worked on, but it really depends on time in regards to making the
          music video myself.
          <br />
          <br />
          For the projects I am continuing to pursue, I mainly did a lot of work
          for The Hollow Child since the deadline was closer compared to the
          other projects.
          <br />
          <br />
          I also started to do work on Fired Before Hired, the game I am doing
          the sound design for. I started with doing the menu music! I gave the
          main game designer a few different clips of different videos to see
          what his vision of what "Office Music" sounded like. This ranged from
          jazz, elevator music, waiting room music, etc. What resonated with him
          the most actually ended up being this waiting room music that had a
          bossa nova vibe to it, so that was the direction I wanted to head
          towards.
          <br />
          <br />
          I usually think of either a soft electric piano or a classical guitar
          for the main chords of a bossa nova song, so I started with looking
          for classical guitar loops on Splice. I would have done it myself but
          I actually don't have a very good mic to capture the sound of a guitar
          and not a lot of quiet areas in my house, and most of the recordings
          of guitar I do are through an audio interface with an electric guitar.
          <br />
          <br />
          Anyways, I found this classical guitar loop playing different chords
          in D minor and I loved it immediately! The artist actually played a
          piano version but I liked the guitar so much more. I imported that
          into Ableton and got my MIDI keyboard and used a soft electric piano
          sound and played around with what chords I wanted to play on top of
          it. I put a lot of focus into making it very soft, so it supports the
          guitar in the background, rather than trying to overpower it because I
          wanted the guitar to be the main focus. I just did a basic 4 chord
          structure and looped it.
          <br />
          <br />
          Then after that I noodled around with a vibraphone and came up with a
          simple melody. Since I was aiming for kind of elevator music, I
          thought it'd be fitting to go up and down the notes in the key and the
          simplicity helps it pass as like waiting room/office music.
          <br />
          <br />
          I thought it needed some percussion so I spent quite a while trying to
          search for one that fit the vibe, and I eventually found one! I added
          some maraccas and a tambourine as well to make it fit better with the
          waiting room theme, the percussion was very light and friendly and
          playful, which was exactly the vibe I was going for! Everything I just
          talked about can be seen here
          <br />
          <br />
          <img src="photos/week7/1.png" alt="" />
          <br />
          <br />
          While I was seacrhing for the percussion, I also found this horn
          sample that I really liked. I was drawn to it for some reason. I added
          it in and asked the game developer if he liked it and he actually
          really liked it and said it was "fire" (his words)! Even though its
          not typical for waiting room music or anything, I think it added to
          the jazzy bossa nova vibe and gave the sound a bit of texture.
          <br />
          <br />
          After this I then started cutting up everything into 3 sections; the
          intro, main loop, and end. Since it is a song for a game, I need to be
          able to have 3 clips of it so I could code that the intro plays, then
          straight after the main loop plays for however long, and then it ends.
          For the intro, I took an open high hat sound and reversed it to work
          as a riser for the start of the percussion part. You can see me do
          this here:
          <br />
          <br />
          <img src="photos/week7/2.png" alt="" />
          <br />
          <br />
          Now that I had all of the parts done, it was just a matter of actually
          assembling the song. I didn't want all of them to play at the same
          time since it makes for a very flat song, theres no variation and
          won't be very interesting. I decided that the main rhythm, which was
          the classical guitar actually doing the bossa nova, would play
          throughout, and the rest would change/get cut off, etc.
          <br />
          <br />
          When the horns were palying, I felt like there was a lot going on, so
          I decided for a part of it, the percussion would stop, highlighting
          the horns and the rhythm, then come back. This part turned out to be
          my favorite part of the entire menu music song! After the horns, I
          felt like the main melody was just being repeated, so I kind of wanted
          to add like a 'bridge' or a B section, but wanted to keep it simple as
          it was just a short loopable song. I just decided to do a little play
          around with the melody, so at least there was some melodic difference
          between that section, and the rest of the song!
          <br />
          <br />
          Then that was done for the menu music! I exported a version where it
          was the intro, main loop twice, then outro so I could gather feedback
          with the song as a whole. The developer absolutely loved it so I'm
          very happy. You can see all the final parts here (I removed the horns
          for some of the parts, but the screenshot is outdated, but everything
          else is right):
          <br />
          <br />
          <img src="photos/week7/3.png" alt="" />
        </p>
      </div>
    </details>

    <!-- ------------------------------------ FUTURE WEEKS TEMPLATE ---------------------------------------------- -->

    <!-- <details class="week" id="week-4">
    <summary>Week </summary>
    <div class="week-content">
      <h3>Reflection</h3>
      <p>...</p>
      <h3>Academic Research</h3>
      <p>...</p>
      <h3>Artistic Research</h3>
      <p>...</p>
      <h3>Technical Research</h3>
      <p>...</p>
      <h3>Progress Report</h3>
      <p>...</p>
    </div>
  </details> -->
  </body>
</html>
