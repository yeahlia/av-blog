<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Audiovision Blog</title>

    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>Audiovision Blog</h1>
    <div class="week-box">
    <h2>Week 1</h2>
    <h3>Reflection</h3>
    This week introduced sound as an emotional and perceptual experience that
    can guide interpretation and narrative. I was particularly interested in the
    exercise which played a score and we had to guess what the intended purpose
    was. I wrote it as a somber feeling mixed with hope, like an anticipation
    for something better when everything is wrong. It was nice to hear everyones
    perceptions of what they heard because they were geared towards the same
    sound, but different answers. It was very impressive when someone got the
    exact answer, I think that attests to how well the sound design was made for
    it.
    <br />
    <br />
    The Four Ways of Knowing stood out, especially participatory knowing (the
    knowing of feeling what it is like to be in an experience). Feeling what its
    like to be in a situation is very important with creating sound design
    (especially for films or games), even if youve never been in that situation
    yourself. Although it didn't just underline the importance to me, it also
    made me start thinking more about how the role of sound can be important for
    audiences to participate more emotionally to a piece of media. A lot of my
    personal projects with sound design have been very focused on realism, but I
    never really thought to consider exactly what I am aiming for with it. Am I
    trying to establish realism to make the visual space more believeable and
    draw attention to it? Am I trying to create certain emotions for things that
    haven't happened on screen? The video shown about how sound can change
    someones perception of visual media also led me to think more about it. A
    moment I found interesting was where it explained how sound could shift
    viewer attention, and how people change where they look on the screen based
    on what they can hear. I never really put 2 and 2 together that since I can
    hint towards something sonically, that would change how people perceive the
    visual media, thus changing where they look, maybe anticipating something. I
    just thought that was very interesting that sound can also be a tool to
    guide visual perception.
  </body>

  <h3>Academic Research</h3>
  I was inspired by how sound could influence perception, and I ended up reading
  this article by Claudia Gorbman (Narrative Film Music), which just talks about
  how music can guide how people interpret narrative meaning. She talked
  specifically about 'unheard melodies' which is basically just how music can
  support narrative meaning in a subtle way, ways that the listener wont really
  realize unless thinking about it. It tied really nicely to what we learnt in
  class. I also went back to this previous paper that I had read previously by
  Chion. He discussed how audio could reflect on visual media in different ways,
  and how you use it is critical. For example, a disconnect in the music can
  create uneasy tension that adds complexity to the visuals, making something
  once seen as normal, into an underlaying feeling of tension.

  <h3>Artistic Research</h3>
  I started to look more deeply into music and emotions tying together,
  listening to my favorite songs and analysing what musically makes me love them
  so much. A specific example is Let Down by Radiohead. Or any radiohead song in
  general. The way that they build atmosphere, the experimental sound, the
  guiding structure, its moody, its spacey. Even i'm not 100% sure the technical
  reasons of why it makes people feel so much. There was a YouTube video I
  <a href="https://www.youtube.com/watch?v=PX2hQdcEvyA">watched</a>
  that I think explained it perfectly, and why it's so good alongside visual
  media. The use of harmony, texture, mood, rhythm. I think its refreshing
  considering a lot of songs nowadays follow certain formulas, but that's a
  completely different topic that I could go into.

  <h3>Technical Research</h3>
  Because of the Gina Moore assignment, i did a lot of research on how to use
  Ableton Live, which is my daw of choice. Experimenting with automation and how
  to make glitches were the highlights. Although I've done it automation before,
  I haven't done it extensively. The more I did it the more shocked I was of how
  it made a difference, especially because if I wanted a sound to go away, I
  just cut it out, but having it play soft in the background added that weight I
  always felt was missing from my sound projects. Learning different ways to
  make glitching sounds was really fun. I layered effects like pitch shifting,
  grain delay and reverb and then used automation to create sudden cuts, fade
  ins and randomized movement, which helped me achieve that glitch texture I was
  looking for.
  <br />
  <br />

  Other than Ableton Live, I actually learnt how to compose a simple orchestra
  piece for this assignment. I recognize that scores aren't my strong suit and I
  wanted to do something that challenged me, especially since the animation I
  chose was around 30 seconds, so I didn't have to make it too long. I watched
  <a href="https://www.youtube.com/watch?v=ZdhdC2wx2Ew">this video</a>
  which was actually extremely helpful and I learnt many new things. I thought
  the violin and viola were basically the same intstrument before this! It was
  interesting how different instruments in brass, woodwind and strings could
  play the same thing and it gave off different emotions and different vibes,
  even though they were in the same frequency spectrum. I particuarly liked the
  hack of making everything on a simple piano, then assigning it to different
  instruments, I definitely think it helped with my workflow as I started
  focusing more on chords and notes and why I wanted to press those, rther than
  being stuck figuring everything all out at once. I would highly reccommend
  that video to anyone looking at how to start with orchestral writing.

  <h3>Progress Report</h3>
  I began by choosing the animation I wanted, then thinking about what direction
  I wanted to go with. This will be written on my report but I originally
  started with a realistic approach but felt that the animation was too
  abstract, and wanted something to fit with that, which is why I chose to do a
  musical score. Of course as mentioned before, I chose to do an orchestral
  piece because of my nonexistent experience. Before watching the video I made
  the mistake of just jumping straigh into, which resulted in a terrible score.
  I just did chords and was playing random lead lines within the key, but it
  sounded terrible:
  <br />
  <br />
  <img src="/photos/week1/original.png" alt="" />
  <br />
  <br />
  My composition improved greatly after I watched the video. I started with a
  rough piano roll and kept refining it until I had a sound and structure I
  liked which consisted of a lead, a second lead, chords and a bass which was
  all I needed!
  <br />
  <br />
  <img src="/photos/week1/pianoroll.png" alt="" />
  <br />
  <br />
  From this I made different groups of the main instruments of strings, and
  assigned the different parts appropriately. The plugin I used was BBC's
  expressive strings, it was super great and useful and free!
  <br />
  <br />
  <img src="photos/week1/strings.png" alt="" />
  <br />
  <br />
  then i did the same for brass, using similar mapping techniques to fill out
  the orchestration
  <br />
  <br />
  <img src="photos/week1/brass.png" alt="" />
  <br />
  <br />
  and then woodwinds.
  <br />
  <br />
  <img src="photos/week1/woodwind.png" alt="" />
  <br />
  <br />
  after that it was just a matter of using automation to create structure! Then
  the sound design was finished! Originally it took up the entire time, but when
  I decided that the glitches would turn it into synths, I cut the midi short. I
  used a bunch of random effects tomake the glitch sounds as I mentioend
  earlier, and then to transition, I layered a abunch of the elad lines with
  different sounds and textures to lead into the glitchiness, but also give it
  some melodic strucutre so the change wasn't too jarring! This completed my
  first draft and I'm still refining, but I have a structure I like and an idea
  I like so I am happy.
  <br />
  <br />
  <img src="photos/week1/transition.png" alt="" />
  </div>

  <div class="week-box">
  <h2>Week 2</h2>
  <h3>Reflection</h3>
  This week in class we analysed the Turn Down for What music video with and
  without sound. I first watched it muted and made notes on what I thought the
  visuals were trying to communicate. Without the audio, it felt like a chaotic
  horror-comedy film where someone’s out of control and something is taking over
  them. The character’s movements were exaggerated and crazy, which made the
  visuals seem comedic, but also strange and hard to follow. Without sound, the
  pacing felt confusing, and the structure was harder to grasp.

  <br />
  <br />
  Once the audio was added back in, the whole thing made more sense. The music
  gave it rhythm and energy, making it feel more like a conventional music
  video, where weird visuals are usually expected. The sound helped me
  anticipate moments like when the chorus began, the movements got more
  repetitive and bizarre. it gave the piece form and made it easier to follow
  and highlighted how sound can structure visuals and change how we interpret
  movement.
  <br />
  <br />

  Since I’ve been away, I haven't able to attend the lectures this week, but I
  did get to watch some of my friend's work online. It was really inspiring to
  see how different people approached the same animations in their own way,
  especially because when I was choosing what animation to do last assignment, I
  had my own ideas for each one. It was interesting to listen to how they
  handled mood, timing, and transitions, and really hammered in how much
  creative interpretation in sound design is just as important as technical
  choices.

  <h3>Academic Research</h3>
  For this week, I mainly referenced two texts that helped shape how I
  approached the Resonance video. The first one was Karen Collins, who talked
  about how ambient textures can help set the emotional tone before anything
  even happens visually. That stuck with me, because I start my projecst by
  focusing on atmosphere rather than realism, and it gave me context on why I
  liked doing that. I wanted the sound to slowly evolve and feel like something
  unstable was underneath, and her ideas made me feel more confident in that
  choice as a lot of the people around me usually start with diegetic sound.
  <br />
  <br />

  The second article I read was by Sonnenschein, where he explains how different
  frequency layers being used can create space and shape how things feel. I used
  this information for the narrative arc, using the lower frequencies at the
  start, then evolving the atmosphere by introducing different sound
  frequencies. By balancing the low end rumbles with higher pitched textures, it
  gave the piece more depth, like something was exploding.

  <h3>Artistic Research</h3>
  For this week, I tried to find artists where the music builds mood and
  atmosphere that makes the audience feel emotional. One of them was Jeff
  Buckley, especially his Grace album. Music alone, his use of dynamics, reverb
  and vocal layering creates this haunting and immersive sound that really stuck
  with me. I was especially immersed with how his songs often start soft and
  open, then swells into intensity in a yearning way. The switch in dynamics is
  something that influenced how I looked at Resonance.
  <br />
  <br />
  I also listened to Johann Johannsson and his score for Arrival. The blending
  of orchestral instruments with electronic textures felt realistic, but
  otherwordly, which really suited the film. I liked the shifts in tone and
  textures to guide the audience through emotion without the need for strong,
  imposing melodies. It highlights the possibility that music can be felt rather
  than heard, and still have a strong impact.

  <h3>Technical Research</h3>
  I explored how to build space and emotion through effects this week. To make
  the sound design feel wide and immersive, I experimented with varying levels
  of reverb, delay, and layering and keeping the dry/wet balance lower at the
  start and opening it up as the visuals progress. I also experimented more with
  automation than I usually do, especially to make certain parts fade in or
  glitch out. Mastering has always been difficult for me, and I watched a few
  different videos to help me with it! One of them being
  <a href="https://www.youtube.com/watch?v=fZdlUiqiDoM">this video</a>
  which talks about different techniques to make audio spaces feel wider

  <h3>Progress Report</h3>
  This week I mainly focused on the completion of Assignment 2.1. I started by
  creating the atmosphere first by layering different horror-themed ambience to
  create the general structure
  <br />
  <br />
  <img src="photos/week2/ambience.png" alt="" />
  <br />
  <br />
  Then I added all the sound effects, including the wet sounds for the bursting
  tentacles (I used a variety of different slime sounds), the cinematic risers
  and faders, etc.
  <br />
  <br />
  <img src="photos/week2/fx.png" alt="" />
  <br />
  <br />
  After that I experimented with different odd and unique sounds to get a more
  interesting texture
  <br />
  <br />
  <img src="photos/week2/unique.png" alt="" />
  <br />
  <br />
  The finally just the static at the start.
  <br />
  <br />
  <img src="photos/week2/static.png" alt="" />
  <br />
  <br />
  After that I spent quite abit of time adding reverb and sending it through
  buses, and EQ shaping and effects to make the sound a bit wider a larger!

  <br />
  <br />
  Other than the Resonance project, I was also able to secure the spot to make
  sound design for one of my friends games! It is a pretty simple game, but it
  is a good introduction into make sound for games, as I have never tried that
  before. I will need to learn Unity and FMOD, and just interactive music in
  general.
  </div>

  <!-- <h2>Week HERE</h2>
  <h3>Reflection</h3>

  <h3>Academic Research</h3>

  <h3>Artistic Research</h3>

  <h3>Technical Research</h3>

  <h3>Progress Report</h3> -->
</html>
