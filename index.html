<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Audiovision Blog</title>

    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>Audiovision Blog</h1>

    <!-- ------------------------------------ WEEK 1 ---------------------------------------------- -->
    <details class="week" id="week-1">
      <summary>Week 1</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          This week introduced sound as an emotional and perceptual experience
          that can guide interpretation and narrative. I was particularly
          interested in the exercise which played a score and we had to guess
          what the intended purpose was. I wrote it as a somber feeling mixed
          with hope, like an anticipation for something better when everything
          is wrong. It was nice to hear everyones perceptions of what they heard
          because they were geared towards the same sound, but different
          answers. It was very impressive when someone got the exact answer, I
          think that attests to how well the sound design was made for it.
        </p>
        <p>
          The Four Ways of Knowing stood out, especially participatory knowing
          (the knowing of feeling what it is like to be in an experience).
          Feeling what its like to be in a situation is very important with
          creating sound design (especially for films or games), even if youve
          never been in that situation yourself. Although it didn't just
          underline the importance to me, it also made me start thinking more
          about how the role of sound can be important for audiences to
          participate more emotionally to a piece of media. A lot of my personal
          projects with sound design have been very focused on realism, but I
          never really thought to consider exactly what I am aiming for with it.
          Am I trying to establish realism to make the visual space more
          believeable and draw attention to it? Am I trying to create certain
          emotions for things that haven't happened on screen? The video shown
          about how sound can change someones perception of visual media also
          led me to think more about it. A moment I found interesting was where
          it explained how sound could shift viewer attention, and how people
          change where they look on the screen based on what they can hear. I
          never really put 2 and 2 together that since I can hint towards
          something sonically, that would change how people perceive the visual
          media, thus changing where they look, maybe anticipating something. I
          just thought that was very interesting that sound can also be a tool
          to guide visual perception.
        </p>

        <h3>Academic Research</h3>
        <p>
          I was inspired by how sound could influence perception, and I ended up
          reading this article by Claudia Gorbman (Narrative Film Music), which
          just talks about how music can guide how people interpret narrative
          meaning. She talked specifically about 'unheard melodies' which is
          basically just how music can support narrative meaning in a subtle
          way, ways that the listener wont really realize unless thinking about
          it. It tied really nicely to what we learnt in class. I also went back
          to this previous paper that I had read previously by Chion. He
          discussed how audio could reflect on visual media in different ways,
          and how you use it is critical. For example, a disconnect in the music
          can create uneasy tension that adds complexity to the visuals, making
          something once seen as normal, into an underlaying feeling of tension.
        </p>

        <h3>Artistic Research</h3>
        <p>
          I started to look more deeply into music and emotions tying together,
          listening to my favorite songs and analysing what musically makes me
          love them so much. A specific example is Let Down by Radiohead. Or any
          radiohead song in general. The way that they build atmosphere, the
          experimental sound, the guiding structure, its moody, its spacey. Even
          i'm not 100% sure the technical reasons of why it makes people feel so
          much. There was a YouTube video I
          <a href="https://www.youtube.com/watch?v=PX2hQdcEvyA">watched</a>
          that I think explained it perfectly, and why it's so good alongside
          visual media. The use of harmony, texture, mood, rhythm. I think its
          refreshing considering a lot of songs nowadays follow certain
          formulas, but that's a completely different topic that I could go
          into.
        </p>

        <h3>Technical Research</h3>
        <p>
          Because of the Gina Moore assignment, i did a lot of research on how
          to use Ableton Live, which is my daw of choice. Experimenting with
          automation and how to make glitches were the highlights. Although I've
          done it automation before, I haven't done it extensively. The more I
          did it the more shocked I was of how it made a difference, especially
          because if I wanted a sound to go away, I just cut it out, but having
          it play soft in the background added that weight I always felt was
          missing from my sound projects. Learning different ways to make
          glitching sounds was really fun. I layered effects like pitch
          shifting, grain delay and reverb and then used automation to create
          sudden cuts, fade ins and randomized movement, which helped me achieve
          that glitch texture I was looking for.
        </p>
        <p>
          Other than Ableton Live, I actually learnt how to compose a simple
          orchestra piece for this assignment. I recognize that scores aren't my
          strong suit and I wanted to do something that challenged me,
          especially since the animation I chose was around 30 seconds, so I
          didn't have to make it too long. I watched
          <a href="https://www.youtube.com/watch?v=ZdhdC2wx2Ew">this video</a>
          which was actually extremely helpful and I learnt many new things. I
          thought the violin and viola were basically the same intstrument
          before this! It was interesting how different instruments in brass,
          woodwind and strings could play the same thing and it gave off
          different emotions and different vibes, even though they were in the
          same frequency spectrum. I particuarly liked the hack of making
          everything on a simple piano, then assigning it to different
          instruments, I definitely think it helped with my workflow as I
          started focusing more on chords and notes and why I wanted to press
          those, rther than being stuck figuring everything all out at once. I
          would highly reccommend that video to anyone looking at how to start
          with orchestral writing.
        </p>

        <h3>Progress Report</h3>
        <p>
          I began by choosing the animation I wanted, then thinking about what
          direction I wanted to go with. This will be written on my report but I
          originally started with a realistic approach but felt that the
          animation was too abstract, and wanted something to fit with that,
          which is why I chose to do a musical score. Of course as mentioned
          before, I chose to do an orchestral piece because of my nonexistent
          experience. Before watching the video I made the mistake of just
          jumping straigh into, which resulted in a terrible score. I just did
          chords and was playing random lead lines within the key, but it
          sounded terrible:
        </p>
        <img src="/photos/week1/original.png" alt="" />
        <p>
          My composition improved greatly after I watched the video. I started
          with a rough piano roll and kept refining it until I had a sound and
          structure I liked which consisted of a lead, a second lead, chords and
          a bass which was all I needed!
        </p>
        <img src="/photos/week1/pianoroll.png" alt="" />
        <p>
          From this I made different groups of the main instruments of strings,
          and assigned the different parts appropriately. The plugin I used was
          BBC's expressive strings, it was super great and useful and free!
        </p>
        <img src="photos/week1/strings.png" alt="" />
        <p>
          then i did the same for brass, using similar mapping techniques to
          fill out the orchestration
        </p>
        <img src="photos/week1/brass.png" alt="" />
        <p>and then woodwinds.</p>
        <img src="photos/week1/woodwind.png" alt="" />
        <p>
          after that it was just a matter of using automation to create
          structure! Then the sound design was finished! Originally it took up
          the entire time, but when I decided that the glitches would turn it
          into synths, I cut the midi short. I used a bunch of random effects
          tomake the glitch sounds as I mentioend earlier, and then to
          transition, I layered a abunch of the elad lines with different sounds
          and textures to lead into the glitchiness, but also give it some
          melodic strucutre so the change wasn't too jarring! This completed my
          first draft and I'm still refining, but I have a structure I like and
          an idea I like so I am happy.
        </p>
        <img src="photos/week1/transition.png" alt="" />
      </div>
    </details>

    <!-- ------------------------------------ WEEK 2 ---------------------------------------------- -->
    <details class="week" id="week-2">
      <summary>Week 2</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          This week in class we analysed the Turn Down for What music video with
          and without sound. I first watched it muted and made notes on what I
          thought the visuals were trying to communicate. Without the audio, it
          felt like a chaotic horror-comedy film where someone’s out of control
          and something is taking over them. The character’s movements were
          exaggerated and crazy, which made the visuals seem comedic, but also
          strange and hard to follow. Without sound, the pacing felt confusing,
          and the structure was harder to grasp.
        </p>
        <p>
          Once the audio was added back in, the whole thing made more sense. The
          music gave it rhythm and energy, making it feel more like a
          conventional music video, where weird visuals are usually expected.
          The sound helped me anticipate moments like when the chorus began, the
          movements got more repetitive and bizarre. it gave the piece form and
          made it easier to follow and highlighted how sound can structure
          visuals and change how we interpret movement.
        </p>
        <p>
          Since I’ve been away, I haven't able to attend the lectures this week,
          but I did get to watch some of my friend's work online. It was really
          inspiring to see how different people approached the same animations
          in their own way, especially because when I was choosing what
          animation to do last assignment, I had my own ideas for each one. It
          was interesting to listen to how they handled mood, timing, and
          transitions, and really hammered in how much creative interpretation
          in sound design is just as important as technical choices.
        </p>

        <h3>Academic Research</h3>
        <p>
          For this week, I mainly referenced two texts that helped shape how I
          approached the Resonance video. The first one was Karen Collins, who
          talked about how ambient textures can help set the emotional tone
          before anything even happens visually. That stuck with me, because I
          start my projecst by focusing on atmosphere rather than realism, and
          it gave me context on why I liked doing that. I wanted the sound to
          slowly evolve and feel like something unstable was underneath, and her
          ideas made me feel more confident in that choice as a lot of the
          people around me usually start with diegetic sound.
        </p>
        <p>
          The second article I read was by Sonnenschein, where he explains how
          different frequency layers being used can create space and shape how
          things feel. I used this information for the narrative arc, using the
          lower frequencies at the start, then evolving the atmosphere by
          introducing different sound frequencies. By balancing the low end
          rumbles with higher pitched textures, it gave the piece more depth,
          like something was exploding.
        </p>

        <h3>Artistic Research</h3>
        <p>
          For this week, I tried to find artists where the music builds mood and
          atmosphere that makes the audience feel emotional. One of them was
          Jeff Buckley, especially his Grace album. Music alone, his use of
          dynamics, reverb and vocal layering creates this haunting and
          immersive sound that really stuck with me. I was especially immersed
          with how his songs often start soft and open, then swells into
          intensity in a yearning way. The switch in dynamics is something that
          influenced how I looked at Resonance.
        </p>
        <p>
          I also listened to Johann Johannsson and his score for Arrival. The
          blending of orchestral instruments with electronic textures felt
          realistic, but otherwordly, which really suited the film. I liked the
          shifts in tone and textures to guide the audience through emotion
          without the need for strong, imposing melodies. It highlights the
          possibility that music can be felt rather than heard, and still have a
          strong impact.
        </p>

        <h3>Technical Research</h3>
        <p>
          I explored how to build space and emotion through effects this week.
          To make the sound design feel wide and immersive, I experimented with
          varying levels of reverb, delay, and layering and keeping the dry/wet
          balance lower at the start and opening it up as the visuals progress.
          I also experimented more with automation than I usually do, especially
          to make certain parts fade in or glitch out. Mastering has always been
          difficult for me, and I watched a few different videos to help me with
          it! One of them being
          <a href="https://www.youtube.com/watch?v=fZdlUiqiDoM">this video</a>
          which talks about different techniques to make audio spaces feel wider
        </p>

        <h3>Progress Report</h3>
        <p>
          This week I mainly focused on the completion of Assignment 2.1. I
          started by creating the atmosphere first by layering different
          horror-themed ambience to create the general structure
        </p>
        <img src="photos/week2/ambience.png" alt="" />
        <p>
          Then I added all the sound effects, including the wet sounds for the
          bursting tentacles (I used a variety of different slime sounds), the
          cinematic risers and faders, etc.
        </p>
        <img src="photos/week2/fx.png" alt="" />
        <p>
          After that I experimented with different odd and unique sounds to get
          a more interesting texture
        </p>
        <img src="photos/week2/unique.png" alt="" />
        <p>The finally just the static at the start.</p>
        <img src="photos/week2/static.png" alt="" />
        <p>
          After that I spent quite abit of time adding reverb and sending it
          through buses, and EQ shaping and effects to make the sound a bit
          wider a larger!
        </p>
        <p>
          Other than the Resonance project, I was also able to secure the spot
          to make sound design for one of my friends games! It is a pretty
          simple game, but it is a good introduction into make sound for games,
          as I have never tried that before. I will need to learn Unity and
          FMOD, and just interactive music in general.
        </p>
      </div>
    </details>

    <!-- ------------------------------------ WEEK 3 ---------------------------------------------- -->
    <details class="week" id="week-3">
      <summary>Week 3</summary>
      <div class="week-content">
        <h3>Reflection</h3>
        <p>
          As I can't attend class, it's pretty difficult to write a reflection
          on ideas raised in class, especially when there isn’t any official
          lecture, but I will try my best!
          <br />
          <br />
          The first class focuses on presentations and feedback for Assignment
          2.1. I showed a few of my family members I am with my project and
          asked their thoughts on it. They aren't sound designers and don't
          really think like them, but this is exactly why I thought their
          feedback was so good. They were able to tell me feedback based on a
          normal consumer level. For this project I generally was told that it
          was very low and that I tend to focus on lower sounds and frequencies,
          leaving the higher ones lacking. I didn't make use of the entire
          frequency spectrum. This made the sound seem a bit muddy or even
          lacking, and hard to make out specific parts. I think especially
          listening to my own work on speakers made this very clear, as I didn’t
          really notice when I was mixing it with headphones in.
          <br />
          <br />
          Another piece of feedback I got was that my mixing could have been
          better. The atmospheric sounds were a bit low and hard to hear, while
          the squelching noise was loud and overbearing, it was basically all
          they could hear. I think feedback like this is especially important,
          and will keep in mind for the future! I think I really need to invest
          in some speakers... It also made me realise how important it is to
          check a mix on different playback systems, what sounds balanced on
          headphones can feel completely different on speakers. This is
          something I’ll try and consciously do for all my future projects.
          <br />
          <br />
          Although, they did like the amount of layers I put in, they felt like
          it had good amounts of sound, was realistic, and they could make the
          connection between the visuals and the audio I chose. They also liked
          the atmosphere I was able to create, and they were particularly
          impressed with the sound design when the tentacles started exploding
          out of the planet. Both the positive and negative feedback is very
          important to me, so I was happy to receive detailed feedback from a
          regular, consumer perspective. It reinforced the idea that while
          technical skill is important, the audience’s emotional and intuitive
          response is ultimately what matters most.
          <br />
          <br />
          The second class had a guest lecturer, and I’m honestly so annoyed I
          missed it because the topics covered sound like they would have been
          incredibly useful. Since I wasn't there I will just talk about my own
          thoughts...
          <br />
          <br />
          I’ve always been a bit confused about the difference between sound
          editing and sound design. A lot of my own process involves editing and
          adding effects to audio from sound libraries, so does that still count
          as editing, or is it considered sound design? Does sound design only
          mean foley or creating audio entirely from scratch? It makes me wonder
          what actually defines a sound designer, especially when I’ve seen
          purists online who refuse to use sound libraries at all, and shame
          anyone who does. Personally, I think there are certain sounds that are
          just impractical or nearly impossible to record yourself, so using a
          library can be the smarter option. I mean, if it already exists, why
          not use it? But I do think people should at least try to build up
          their own sound repertoire so they don't have to rely on sound
          libraries forever.
          <br />
          <br />
          I also think that knowing how to make exactly what you're thinking is
          incredibly hard, but super rewarding once you are able to. As with all
          creative practices, you get the hang of it once you start doing it
          more, and being in this studio and having to make audio for visuals
          every week so far has actually shown a significant improvement in my
          skills, which I am both surprised and thankful for. Missing the
          lecture makes me want to spend some time researching the roles and
          workflows the lecturer discussed, because I can already see that
          understanding the boundary between design and editing could help me
          plan my projects more efficiently.
          <br />
          <br />
          This also made me think about the phenomenon of the Wilhelm scream,
          which is that infamous stock sound effect everyone recognises. When
          it’s used, it can snap the audience out of immersion because they
          immediately associate it with other films. I think that raises an
          interesting question about when familiarity adds charm or nostalgia
          versus when it becomes distracting. In this case, I can see how using
          sound libraries can be not ideal, especially for big blockbuster
          films. Like surely they could have filmed a guy screaming instead of
          choosing to use a stock sound? I mean they have such big budgets
          right? This makes me reflect on my own sound choices, maybe I should
          be more conscious of using highly recognisable sounds unless I’m
          intentionally going for humour.
          <br />
          <br />
          Anyways, the rest of the lecture content, things like EQ, editing
          concepts, layering techniques, emotional architecture, and more, all
          sound super interesting. I’d love to dive deeper into those topics, so
          if the lecturer presents again or if there’s an online recording
          somewhere, I’d definitely want to check it out. In the meantime, I
          will probably explore some online tutorials or breakdowns from
          professional sound editors to get a better grasp of these concepts, so
          that next time I’m working on a project, I can apply more deliberate
          choices in rhythm, layering, and tonal shaping.
        </p>

        <h3>Academic Research</h3>
        <p>
          This week I read Zwicker and Fastl's Psychoacoustics: Facts and Models
          to understand more about how frequency content affects how we perceive
          time and motion in sound. They talk about how removing higher
          frequencies can make things feel slower and heavier, which is exactly
          what I needed for the slow-motion sections of my project. It gave me
          the idea to use frequency filtering instead of pitch-shifting or
          time-stretching. It was nice to have theory backed reasonings for my
          work, as I did notice a significant difference by using the pitch
          filtering because it was exactly what I was aiming for.
          <br /><br />
          I also read Altmans Sound Theory, Sound Practice which kinda goes into
          how sound and image work together to make meaning. Although this made
          sense to me already and in my head I thought this was obvious, I
          started to think more intentionally about my design choices, and why I
          chose a specific pad sound. I realized I chose it because
          subconsciously I wanted the pad to build up in the same way that the
          cube does visually. I connected this with the pitch frequency
          filtering, where the sound slowly regains its higher frequencies and
          the audience will get reinforcement that the video is progressing, and
          just gives it structure overall.
          <br /><br />
          Holman's Sound for Film and Television was also another useful text
          for this week. He talks about matching the texture of sound to the
          visuals, which made me change my EQ choices for the Lego building
          sound. I knew that the Lego sound felt out of place, but with EQ I was
          able to get it to feel shinier and cleaner which matches the visuals
          aesthetics way more. I did this by boosting the higher end, lowering
          the bottom and keeping the mids relatively the same to still maintain
          that tactile feeling of the original recording!
        </p>

        <h3>Artistic Research</h3>
        <p>
          I was rewatching a few old Pixar films recently and one of them
          particularly caught my attention sound wise. Wall-E's different sounds
          and expressions are made by using everyday objects to make sound, yet
          still felt so emotional and believable and had this weight to it. It
          felt authentic. I was inspired by this, as I thought it was so
          impressive how this sound was made and edited. It was what gave me the
          idea to find everyday objects for this weeks project, which ended up
          being Lego. It is a familiar and nostalgic sound and while its not a
          direct match for the sound I imaged for the cube, I could process it
          but still keep that tactile identity.
          <br /><br />
          I also listened to Royji Ikeda, who makes super minimalist and precise
          tones to make his sound. It's very clean and he uses a lot of control
          and timing to make his music (though I would just call it sounds
          rather than music). This is what made me want to try limiting the
          amount of sounds I can use, to try getting the full potential out of
          the sounds I already have in the project, by using control and timing.
          Ikeda showed me that simplicity can be just as powerful and impactful
          as complexity, and I really wanted to experiment with that in my
          project this week.
          <br /><br />
        </p>

        <h3>Technical Research</h3>
        <p>
          This week I mainly focused on how to make glassy and shimmery sounds
          from scratch, as I tend to rely on a lot of sound libraries for it.
          Although there is nothing wrong with using sound libraries and
          manipulating the sound, I thought it would be best to at least learn
          how to make some so I could build my own sound effect library. I
          followed this
          <a
            href="https://www.youtube.com/watch?v=CEZHfQOqQxQ&ab_channel=UnderdogElectronicMusicSchool"
            >YouTube video</a
          >
          which uses FM synthesis to make those glassy sounds. He is a very good
          teacher, calm and explains himself well, so I will be looking more
          into his other videos in the future. Although he used an Ableton
          feature that I don't have, I found the skills to be transferrable to
          other budget options and plugins, as he explains why he does each
          step, and even showing the difference between each parameter in the
          different effects he uses. It was a super informative video and I was
          able to make a few sounds I liked! <br /><br />
          I also watched
          <a href="https://www.youtube.com/watch?v=UQy7VHm-Ucg">this video</a>
          which is a tutorial on how the PaulXStretch plugin works. It goes
          super in depth and explained all the features and I can't believe the
          plug in is free. Although I ended up having some technical troubles
          and couldn't use it for this weeks projects, I am excited to fix it
          and use it in the future! Especially the ability to change different
          harmonics and use it in conjuction with other effects would make for
          really good experimenting.
        </p>

        <h3>Progress Report</h3>
        <p>
          I had a lot of projects to work on this week! I had a bunch of people
          reach out to me to do the sound design for their projects but
          unfortunately I wasn't able to do all of them, even though they were
          all such interesting concepts. One of the projects I chose to work on
          was "The Reconnect". Caroline, the animator, sent me her draft
          animatic, as well as a sound design brief and the project concept. I
          really appreciated how organized and professional the documents she
          gave me was, it was super helpful to decide what I wanted to do for
          her project, while bringing her vision to life. She gave me a small
          part of her animatic that was confirmed to stay the same, so I worked
          on that scene.
        </p>
        <p>
          I first started by making the ambience of the scene, like I usually
          do. I layered a few different textures to make the structure of the
          scene. Though it was pretty hard because it was a pretty small scene,
          but I'm sure when I work on the full thing, I'll be able to transition
          between sounds better, without sounding too abrupt.
        </p>
        <img src="photos/week3/reconnect2.png" alt="" />
        <p>Then I worked on the diegetic sound:</p>
        <img src="photos/week3/reconnect3.png" alt="" />
        <p>
          Then worked on the non-diegetic sound, and transitional sounds and
          wooshes:
        </p>
        <img src="photos/week3/reconnect1.png" alt="" />
        <p>
          And that was basically done for the scene! Again, it was pretty short
          and I kept the narration that was in the original animatic (which is
          why it might sound bad in terms of the mix, because the narration was
          also a draft), but I am happy with the general idea, and so was
          Caroline. She mentioned some changes when she finalizes the animation
          but it is a good start! You can watch the draft
          <a href="https://youtu.be/UgO7CwLyiRE">here</a>!
        </p>
        <p>
          Then I also worked (and finished) my Assignment 2.2 as I am busy next
          week and won't have time to do it! I first began by making my own pad
          sound using the tutorial I showed you earlier. I used his tip of
          turning the midi file into an audio file and used that to make all the
          changes, and added it into my personal sound library.
        </p>
        <img src="photos/week3/own.png" alt="" />
        <p>
          I then experimented with grain delay, using the pitch parameter to try
          and simulate the slow motion effect:
        </p>
        <img src="photos/week3/graindelay.png" alt="" />
        <p>
          I wasn't a fan of this as I wrote on my report, and decided to try
          using the PaulXStretch plugin:
        </p>
        <img src="photos/week3/paulstretch.png" alt="" />
        <p>
          But again, wasn't a fan and there was a steep learning curve and
          technical difficulties. I then decided to use frequencies filtering
          instead, which I was a fan of!:
        </p>
        <img src="photos/week3/padauto.png" alt="" />
        <p>
          It sounded exactly like I wanted. And then I did it for the lego
          building sound as well, with less of a sweep:
        </p>
        <img src="photos/week3/legoauto.png" alt="" />
        <p>
          Then it was just a matter of finishing touches! I added the sparkles
          that go throughout the entire video, but used volume automation so it
          was more prominent in the later half of the video:
        </p>
        <img src="photos/week3/sparkle.png" alt="" />
        <p>
          And that was done for AV2.2! I just had to write the report. But other
          than that, I also decided to use one of my old song projects for the
          music video I will do for this semester. Although I haven't 100%
          decided it will be a music video, I was also thinking of doing a light
          show for the Capitol Theatre! Which I thought would be cool. Anyways I
          went through a bunch of my old guitar files, and found this one I
          liked, where it was in the shoegaze genre, and I added some lead
          guitar over it and messed with the effects a bit, as well as adding
          the much needed drums. Although I am not a drummer and had to MIDI the
          entire thing, when I get back to Australia I'll probably use real
          drums and fix up the guitar parts, as well as add more instruments.
          You can watch the WIP of the song
          <a href="https://youtu.be/6MhdX7PVxWc">here</a>. I chose that song
          because it's very atmospheric, but still incorporates live instruments
          so it is the best of both worlds! (and I am a huge shoegaze fan)
        </p>
      </div>
    </details>

    <!-- ------------------------------------ FUTURE WEEKS TEMPLATE ---------------------------------------------- -->
    <!-- Copy this block and change the id/summary text for Weeks 4–12
  <details class="week" id="week-4">
    <summary>Week 4</summary>
    <div class="week-content">
      <h3>Reflection</h3>
      <p>...</p>
      <h3>Academic Research</h3>
      <p>...</p>
      <h3>Artistic Research</h3>
      <p>...</p>
      <h3>Technical Research</h3>
      <p>...</p>
      <h3>Progress Report</h3>
      <p>...</p>
    </div>
  </details>
  --></body>
</html>
